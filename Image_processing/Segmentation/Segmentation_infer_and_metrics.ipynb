{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T07:00:48.735229Z",
     "start_time": "2024-10-17T07:00:36.153841Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import img_to_array, load_img, array_to_img\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def unet_model(n_classes=1, IMG_HEIGHT=512, IMG_WIDTH=288, IMG_CHANNELS=3):\n",
    "#Build the model\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    #Expansive path\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T07:00:48.766224Z",
     "start_time": "2024-10-17T07:00:48.736221Z"
    }
   },
   "id": "7bde34a5c288ef34",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 2.5412 - mean_io_u: 0.4126\n",
      "Epoch 1: val_mean_io_u improved from -inf to 0.39615, saving model to modelo_unet.h5\n",
      "70/70 [==============================] - 32s 387ms/step - loss: 2.5412 - mean_io_u: 0.4126 - val_loss: 0.6143 - val_mean_io_u: 0.3961\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5242 - mean_io_u: 0.4071\n",
      "Epoch 2: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 51s 736ms/step - loss: 0.5242 - mean_io_u: 0.4071 - val_loss: 0.5276 - val_mean_io_u: 0.3961\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4766 - mean_io_u: 0.4071\n",
      "Epoch 3: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 36s 504ms/step - loss: 0.4766 - mean_io_u: 0.4071 - val_loss: 0.5370 - val_mean_io_u: 0.3961\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5335 - mean_io_u: 0.4071\n",
      "Epoch 4: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 32s 459ms/step - loss: 0.5335 - mean_io_u: 0.4071 - val_loss: 0.5481 - val_mean_io_u: 0.3961\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.5205 - mean_io_u: 0.4071\n",
      "Epoch 5: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 42s 605ms/step - loss: 0.5205 - mean_io_u: 0.4071 - val_loss: 0.5258 - val_mean_io_u: 0.3961\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4992 - mean_io_u: 0.4071\n",
      "Epoch 6: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 31s 445ms/step - loss: 0.4992 - mean_io_u: 0.4071 - val_loss: 0.5159 - val_mean_io_u: 0.3961\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4891 - mean_io_u: 0.4071\n",
      "Epoch 7: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 35s 500ms/step - loss: 0.4891 - mean_io_u: 0.4071 - val_loss: 0.5119 - val_mean_io_u: 0.3961\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4839 - mean_io_u: 0.4071\n",
      "Epoch 8: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 35s 502ms/step - loss: 0.4839 - mean_io_u: 0.4071 - val_loss: 0.5105 - val_mean_io_u: 0.3961\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4799 - mean_io_u: 0.4071\n",
      "Epoch 9: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 38s 546ms/step - loss: 0.4799 - mean_io_u: 0.4071 - val_loss: 0.5049 - val_mean_io_u: 0.3961\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.4525 - mean_io_u: 0.4071\n",
      "Epoch 10: val_mean_io_u did not improve from 0.39615\n",
      "70/70 [==============================] - 31s 449ms/step - loss: 0.4525 - mean_io_u: 0.4071 - val_loss: 0.4823 - val_mean_io_u: 0.3961\n"
     ]
    }
   ],
   "source": [
    "# Antiguo train\n",
    "# Obtén la lista de archivos\n",
    "#dir_imagenes = r\"C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\dataSet_segmentacion\\train\\input_images/\"\n",
    "#dir_mascaras = r\"C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\dataSet_segmentacion\\train\\output_masks/\"\n",
    "\n",
    "#archivos_imagenes = os.listdir(dir_imagenes)\n",
    "#archivos_mascaras = os.listdir(dir_mascaras)\n",
    "\n",
    "# Lee imágenes y máscaras y almacénalas en listas\n",
    "#imagenes = []\n",
    "#mascaras = []\n",
    "#for img_file, mask_file in zip(archivos_imagenes, archivos_mascaras):\n",
    "    \n",
    "#    img_path = os.path.join(dir_imagenes, img_file)\n",
    "#    mask_path = os.path.join(dir_mascaras, mask_file)\n",
    "    \n",
    "#    img = cv2.imread(img_path)\n",
    "#    img = cv2.resize(img, (512, 288))\n",
    "    \n",
    "#    mask = cv2.imread(mask_path, cv2.IMREAD_ANYDEPTH)\n",
    "#    mask = cv2.resize(mask, (512, 288))\n",
    "    \n",
    "#    imagenes.append(img)\n",
    "#    mascaras.append(mask[:,:])\n",
    "\n",
    "# Convierte listas a matrices numpy\n",
    "#imagenes = np.array(imagenes)\n",
    "#mascaras = np.array(mascaras)\n",
    "\n",
    "#mascaras = np.expand_dims(mascaras, axis = -1)\n",
    "\n",
    "# Divide los datos en entrenamiento y prueba\n",
    "#X_train, X_test, y_train, y_test = train_test_split(imagenes, mascaras, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normaliza las imágenes dividiendo por 255\n",
    "#X_train = X_train.astype('float32')# / 255.\n",
    "#X_test = X_test.astype('float32')# / 255.\n",
    "\n",
    "#y_train = y_train.astype('float32') / 1.\n",
    "#y_test = y_test.astype('float32') / 1.\n",
    "\n",
    "#modelo = unet_model(n_classes=1, IMG_HEIGHT=X_train.shape[1], IMG_WIDTH=X_train.shape[2], IMG_CHANNELS=X_train.shape[3])\n",
    "\n",
    "# Compila el modelo\n",
    "#modelo.compile(optimizer=Adam(), loss=binary_crossentropy, metrics=[MeanIoU(num_classes=2)])\n",
    "\n",
    "# Define el callback para guardar el modelo con la mejor precisión en el conjunto de prueba\n",
    "#checkpoint = ModelCheckpoint('modelo_unet.h5', monitor='val_mean_io_u', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Entrena el modelo\n",
    "\n",
    "#historia = modelo.fit(X_train, y_train, batch_size=4, epochs=10, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "# Guarda el modelo entrenado\n",
    "#modelo.save(r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\dataSet_segmentacion\\train/unet_Lescala_Unnormalized.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T10:58:14.577413Z",
     "start_time": "2024-09-24T10:51:12.888907Z"
    }
   },
   "id": "c5cbe97f8617e159",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "modelo = unet_model(n_classes=1, IMG_HEIGHT=288, IMG_WIDTH=512, IMG_CHANNELS=3)\n",
    "modelo.load_weights(r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\dataSet_segmentacion\\train/unet_Lescala_Unnormalized.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-24T11:06:49.364830Z",
     "start_time": "2024-09-24T11:06:49.097086Z"
    }
   },
   "id": "21a579996a7ad697",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mascara_agua_path = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\mascara_agua_segmentacion/mascara_agua_lescala_2.jpg'\n",
    "mascara_javi = r'C:\\Users\\aquacorp\\Desktop\\mask_javi.jpg'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T07:00:48.781737Z",
     "start_time": "2024-10-17T07:00:48.768224Z"
    }
   },
   "id": "8580764f982e22c3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "modelo = load_model(r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\dataSet_segmentacion\\imagenes_post_mov/unet_ampliado_28sep_16oct.h5')\n",
    "\n",
    "path_img_ = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\dataSet_segmentacion\\imagenes_post_mov\\originales/20241003050943.tif'\n",
    "mascara_agua_path = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\mascara_agua_segmentacion/mask_lescala_mov_camara.jpg'\n",
    "#mask_GT_path = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Cidacos_HOMO\\Segmentacion/Validacion_set/GT_mask/m_20240322172839.jpg'\n",
    "\n",
    "img_ = cv2.imread(path_img_)\n",
    "img_ = cv2.resize(img_, (128, 128))\n",
    "img_ = np.expand_dims(img_, axis=0)\n",
    "\n",
    "#mask_GT_ = cv2.imread(mask_GT_path, cv2.IMREAD_ANYDEPTH)\n",
    "#mask_GT_ = cv2.resize(mask_GT_, (512, 288))\n",
    "\n",
    "mascara_agua = cv2.imread(mascara_agua_path)\n",
    "mascara_agua = cv2.resize(mascara_agua, (128, 128))\n",
    "\n",
    "_, mascara_agua_bin = cv2.threshold(mascara_agua, 128, 1, cv2.THRESH_BINARY)\n",
    "mascara_agua_bin = np.uint8(mascara_agua_bin)\n",
    "\n",
    "#_, mask_GT = cv2.threshold(mask_GT_, 128, 1, cv2.THRESH_BINARY)\n",
    "#mask_GT = np.uint8(mask_GT)\n",
    "\n",
    "pred_bruto = modelo.predict(img_/255, verbose=False)\n",
    "pred_bruto = np.squeeze(pred_bruto, axis = 0)\n",
    "img_ = np.squeeze(img_, axis = 0)\n",
    "_, pred_bruto = cv2.threshold(pred_bruto, 0.7, 1, cv2.THRESH_BINARY)\n",
    "pred_bruto = np.uint8(pred_bruto)\n",
    "pred_bruto_inv = 1 - pred_bruto\n",
    "\n",
    "mascara_predicha = pred_bruto*mascara_agua_bin[:,:,0]\n",
    "transparencia = 0.2\n",
    "\n",
    "mask_pred_rgb = np.zeros_like(img_)\n",
    "mask_pred_rgb[:,:,2] = mascara_predicha*255\n",
    "\n",
    "composicion_pred = cv2.addWeighted(mask_pred_rgb, transparencia, img_, 1 - transparencia, 0)\n",
    "cv2.imshow('Prediccion', composicion_pred)\n",
    "cv2.imshow('Mascara', mask_pred_rgb)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T07:15:43.768341Z",
     "start_time": "2024-10-17T07:15:37.718799Z"
    }
   },
   "id": "c9cb62b7aae62f14",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   1%|          | 2/208 [00:00<01:17,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   2%|▏         | 4/208 [00:00<00:53,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   3%|▎         | 6/208 [00:01<00:42,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   4%|▍         | 8/208 [00:01<00:36,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   5%|▍         | 10/208 [00:01<00:32,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   6%|▌         | 12/208 [00:02<00:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   6%|▋         | 13/208 [00:02<00:32,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n",
      "pred_bruto\n",
      "(512, 288)\n",
      "mascara_agua_bin\n",
      "(512, 288, 3)\n",
      "mascara_predicha\n",
      "(512, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando máscaras:   7%|▋         | 14/208 [00:02<00:38,  5.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 25\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m#img_ = cv2.resize(img_, (512, 288))\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m#img_ = cv2.resize(img_, (288, 512))\u001B[39;00m\n\u001B[0;32m     23\u001B[0m img_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(img_, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 25\u001B[0m pred_bruto \u001B[38;5;241m=\u001B[39m \u001B[43mmodelo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m255\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m#pred_bruto = modelo.predict(img_, verbose=False)[0]\u001B[39;00m\n\u001B[0;32m     27\u001B[0m pred_bruto \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(pred_bruto, axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\keras\\engine\\training.py:2064\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2061\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m original_pss_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2062\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribution_strategy \u001B[38;5;241m=\u001B[39m original_pss_strategy\n\u001B[1;32m-> 2064\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msync_to_numpy_or_python_type\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_outputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\keras\\utils\\tf_utils.py:607\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type\u001B[1;34m(tensors)\u001B[0m\n\u001B[0;32m    604\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\n\u001B[0;32m    605\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mndim(t) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m--> 607\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_single_numpy_or_python_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    912\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    913\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    915\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 916\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [func(\u001B[38;5;241m*\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    917\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    912\u001B[0m flat_structure \u001B[38;5;241m=\u001B[39m (flatten(s, expand_composites) \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m structure)\n\u001B[0;32m    913\u001B[0m entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mflat_structure)\n\u001B[0;32m    915\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pack_sequence_as(\n\u001B[1;32m--> 916\u001B[0m     structure[\u001B[38;5;241m0\u001B[39m], [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m entries],\n\u001B[0;32m    917\u001B[0m     expand_composites\u001B[38;5;241m=\u001B[39mexpand_composites)\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\keras\\utils\\tf_utils.py:601\u001B[0m, in \u001B[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_to_single_numpy_or_python_type\u001B[39m(t):\n\u001B[0;32m    599\u001B[0m   \u001B[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001B[39;00m\n\u001B[0;32m    600\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, tf\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m--> 601\u001B[0m     t \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    602\u001B[0m   \u001B[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001B[39;00m\n\u001B[0;32m    603\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, (np\u001B[38;5;241m.\u001B[39mndarray, np\u001B[38;5;241m.\u001B[39mgeneric)):\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001B[0m, in \u001B[0;36m_EagerTensorBase.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m \n\u001B[0;32m   1138\u001B[0m \u001B[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1156\u001B[0m \u001B[38;5;124;03m    NumPy dtype.\u001B[39;00m\n\u001B[0;32m   1157\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001B[39;00m\n\u001B[1;32m-> 1159\u001B[0m maybe_arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m maybe_arr\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(maybe_arr, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;28;01melse\u001B[39;00m maybe_arr\n",
      "File \u001B[1;32m~\\Desktop\\Repo_Aquacorp\\venv_py3.9\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001B[0m, in \u001B[0;36m_EagerTensorBase._numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_numpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1124\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1126\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#modelo = unet_model(n_classes=1, IMG_HEIGHT=288, IMG_WIDTH=512, IMG_CHANNELS=3)\n",
    "\n",
    "modelo = load_model(r'C:\\Users\\aquacorp\\Desktop\\espacios_latentes\\Lescala\\modelo_segmentacion_load_tf/unet_Lescala.h5')\n",
    "path_imges = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\espumas_azules_22-23sep_2024\\originales'\n",
    "path_results = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\espumas_azules_22-23sep_2024\\predicciones_modelo_nuevo'\n",
    "mascara_agua_path = r'C:\\Users\\aquacorp\\Desktop\\Imagenes\\Lescala\\mascara_agua_segmentacion/mascara_agua_lescala_2.jpg'\n",
    "\n",
    "transparencia = 0.2\n",
    "\n",
    "mascara_agua = cv2.imread(mascara_agua_path)\n",
    "#mascara_agua = cv2.resize(mascara_agua, (512, 288))\n",
    "mascara_agua = cv2.resize(mascara_agua, (288, 512))\n",
    "\n",
    "_, mascara_agua_bin = cv2.threshold(mascara_agua, 128, 1, cv2.THRESH_BINARY)\n",
    "mascara_agua_bin = np.uint8(mascara_agua_bin)\n",
    "\n",
    "total = len(os.listdir(path_imges))\n",
    "for img in tqdm(os.listdir(path_imges), desc=\"Generando máscaras\", total = total):\n",
    "    im_pat = os.path.join(path_imges, img)\n",
    "    img_ = load_img(im_pat, target_size=(512, 288))\n",
    "    #img_ = cv2.resize(img_, (512, 288))\n",
    "    #img_ = cv2.resize(img_, (288, 512))\n",
    "    img_ = np.expand_dims(img_, axis=0)\n",
    "    \n",
    "    pred_bruto = modelo.predict(img_/255, verbose=False)\n",
    "    #pred_bruto = modelo.predict(img_, verbose=False)[0]\n",
    "    pred_bruto = np.squeeze(pred_bruto, axis = 0)\n",
    "    #img_ = np.squeeze(img_, axis = 0)\n",
    "    _, pred_bruto = cv2.threshold(pred_bruto, 0.3, 1, cv2.THRESH_BINARY)\n",
    "    #pred_bruto = (pred_bruto > 0.5).astype(np.uint8)\n",
    "    pred_bruto = np.uint8(pred_bruto)\n",
    "    pred_bruto_inv = 1 - pred_bruto\n",
    "    #print(mascara_predicha.shape)\n",
    "    print('pred_bruto')\n",
    "    print(pred_bruto.shape)\n",
    "    print('mascara_agua_bin')\n",
    "    print(mascara_agua_bin.shape)\n",
    "    mascara_predicha = pred_bruto*mascara_agua_bin[:,:,0]\n",
    "    print('mascara_predicha')\n",
    "    print(mascara_predicha.shape)\n",
    "    mask_pred_rgb = np.zeros(shape=(512, 288, 3), dtype='uint8')\n",
    "    \n",
    "    mask_pred_rgb[:,:,2] = mascara_predicha*255\n",
    "    \n",
    "    #print()\n",
    "    img_ = np.squeeze(img_, axis=0)\n",
    "    composicion_pred = cv2.addWeighted(mask_pred_rgb, transparencia, img_, 1 - transparencia, 0)\n",
    "    \n",
    "    # Calculo de % de espuma\n",
    "    mask_agua_inv = 1 - mascara_agua_bin\n",
    "\n",
    "    neg_0_y_1 = mascara_predicha - mask_agua_inv[:,:,0]\n",
    "    \n",
    "    pixel_agua = np.sum(neg_0_y_1 == 0)\n",
    "    pixel_espuma = np.sum(neg_0_y_1 == 1)\n",
    "    \n",
    "    porcentaje = 100*pixel_espuma/(pixel_agua + pixel_espuma)\n",
    "    # Fin calculo de % espuma\n",
    "    \n",
    "    dir_save_mask = path_results + f'/{int(porcentaje)}%_' + img\n",
    "    \n",
    "    cv2.imwrite(dir_save_mask, composicion_pred)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T07:15:33.448623Z",
     "start_time": "2024-10-17T07:15:29.602841Z"
    }
   },
   "id": "9b57f48315e8e3d2",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aquí vamos a calcular las métricas. Por un lado se va a calcular la IoU para ver lo bien que funciona el modelo.\n",
    "Por otro lado se va a dar el resultado 'final' que se proporciona como % de grasas sobre el agua.\n",
    "\n",
    "Aquí vamos a calcular el % de ocupación de grasas. Se hace de la siguiente manera\n",
    "Se lee la máscara de agua para acotar la zona. La máscara tiene a 0 los pixeles donde no hay agua y 1 los pixeles\n",
    "donde sí que hay agua. Se sumarán los pixeles donde sí hay agua para tener el denominador del % de la ocupación de grasas.\n",
    "Por otro lado, se suman los pixeles en blanco de la máscara predicha, pues en este caso son los píxeles blancos es donde hay grasa.\n",
    "El resultado de ocupación será el cociente entre las magnitudes descritas multiplicado por 100. \n",
    "Este resultado se acompña de  la imagen de la grasa cubierta por la máscara de grasa en versión traslucida.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3e40d4c9b876bde"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje predicho: 37%\n",
      "Porcentaje GT: 79%\n"
     ]
    }
   ],
   "source": [
    "pixeles_agua_total = np.count_nonzero(mascara_agua_bin == 1)/3\n",
    "pixeles_grasa_pred = np.count_nonzero(mascara_predicha == 1)\n",
    "pixeles_grasa_GT = np.count_nonzero(mask_GT == 1)\n",
    "\n",
    "porcentaje_grasa_pred = 100 * (pixeles_grasa_pred / pixeles_agua_total)\n",
    "p_grasa_pred = str(int(porcentaje_grasa_pred)) + '%'\n",
    "print('Porcentaje predicho: ' + p_grasa_pred)\n",
    "\n",
    "porcentaje_grasa_GT = 100 * (pixeles_grasa_GT / pixeles_agua_total)\n",
    "p_grasa_GT = str(int(porcentaje_grasa_GT)) + '%'\n",
    "print('Porcentaje GT: ' + p_grasa_GT)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T14:52:00.337807Z",
     "start_time": "2024-05-14T14:52:00.323742Z"
    }
   },
   "id": "6bd30de66ae6d148",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transparencia = 0.2\n",
    "\n",
    "mask_pred_rgb = cv2.cvtColor(mascara_predicha*255, cv2.COLOR_GRAY2RGB)\n",
    "composicion_pred = cv2.addWeighted(mask_pred_rgb, transparencia, img_, 1 - transparencia, 0)\n",
    "\n",
    "mask_GT_rgb = cv2.cvtColor(mask_GT*255, cv2.COLOR_GRAY2RGB)\n",
    "composicion_GT = cv2.addWeighted(mask_GT_rgb, transparencia, img_, 1 - transparencia, 0)\n",
    "\n",
    "cv2.imshow(p_grasa_pred + ' Prediccion', composicion_pred)\n",
    "cv2.imshow(p_grasa_GT + ' GT', composicion_GT)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T15:03:40.374034Z",
     "start_time": "2024-05-14T15:03:38.393708Z"
    }
   },
   "id": "fc20570dfc073450",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir de aquí se van a hacer calculos de IoU. La filosofía de este cálculo será sumar la máscara Ground Truth y la máscara\n",
    "predicha. Los puntos donde coincidan 1 dará como resultado 2, los puntos donde no coincidan se mantendrán como 1 y se quedaran\n",
    "en 0 las zonas donde coincidan en que no hay grasas. La intersección serían todos los pixeles donde el valor es 2, la unión será\n",
    "todos los pixeles que tengan valor 1 o 2. La métrica IoU será el cociente interseccion/union. Se puede expresar en % o entre 0 y 1.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86dc41156f8784de"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.659517955528436\n"
     ]
    }
   ],
   "source": [
    "suma_GT_pred = mask_GT + mascara_predicha\n",
    "I = np.count_nonzero(suma_GT_pred == 2)\n",
    "U = np.count_nonzero(suma_GT_pred == 2) + np.count_nonzero(suma_GT_pred == 1)\n",
    "IoU = I/U\n",
    "print(IoU*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-10T11:20:51.857405Z",
     "start_time": "2024-05-10T11:20:51.843400Z"
    }
   },
   "id": "9aae327f4b555ede",
   "execution_count": 161
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
